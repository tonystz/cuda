{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonystz/gitpod/blob/main/pycuda_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2JZt1GL5D6W"
      },
      "source": [
        "# Introduction to CUDA and PyCUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g92eSBn5FlC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df=pd.read_csv('drive/MyDrive/a.csv').dropna()\n",
        "print(df)\n",
        "a= df.to_numpy()\n",
        "print(a)\n",
        "print(a.shape,a.size,a.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# python to check risk IP, check threshhold: >5 times within 6 minute"
      ],
      "metadata": {
        "id": "muSDcrJ-TjLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import csv\n",
        "import socket, struct\n",
        "import numpy as np\n",
        "\n",
        "ip2long=lambda ip:struct.unpack(\"!L\", socket.inet_aton(ip))[0]\n",
        "long2ip=lambda long:socket.inet_ntoa(struct.pack('!L', long))\n",
        "date2int=lambda current_date: current_date.year*10000000000 + current_date.month * 100000000 +  current_date.day * 1000000 + current_date.hour*10000 + current_date.minute*100 + current_date.second\n",
        "\n",
        "#pre-process data\n",
        "hack_type={\n",
        "    'Ftp访问日志':0,\n",
        "    'SQL 注入':1,\n",
        "    'Web Shell攻击':2,\n",
        "    '暴力破解':3,\n",
        "    '端口扫描':4,\n",
        "    '缓冲区溢出攻击':5,\n",
        "    '弱口令漏洞':6\n",
        "}\n",
        "\n",
        "numdata=[]\n",
        "with open('drive/MyDrive/a.csv', newline='') as csvfile:\n",
        "    data = csv.reader(csvfile)\n",
        "    next(data) #skip header\n",
        "    for row in data:\n",
        "        if len(row[0]) == 0: continue\n",
        "        numdata.append([date2int(datetime.strptime(row[1]+' '+row[2],'%Y/%m/%d %H:%M:%S')),hack_type.get(row[3],-1),ip2long(row[4])])\n",
        "        print(row)\n",
        "print('number data',numdata)\n",
        "a=np.array(numdata,dtype=np.uint64)\n",
        "\n",
        "# r=np.zeros(a.shape,dtype=a.dtype)\n",
        "#group data\n",
        "rdict={}\n",
        "for i in a:\n",
        "    if i[2] in rdict:\n",
        "        rdict[i[2]][0] +=1\n",
        "        rdict[i[2]][1].append(i[0])\n",
        "    else:\n",
        "        rdict[i[2]]=[1,[i[0]]]\n",
        "\n",
        "print('rdict',rdict)\n",
        "\n",
        "# check threshhold: >5 within 6 minute\n",
        "th_count=5\n",
        "th_min=6*100\n",
        "\n",
        "for k,v in rdict.items():\n",
        "    if v[0] > th_count:\n",
        "        avg_time=int(sum(v[1])/len(v[1]))\n",
        "        if [i for i in v[1] if i < avg_time + th_min]:\n",
        "            print(long2ip(k))"
      ],
      "metadata": {
        "id": "Np2C3LBBevBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GUP version"
      ],
      "metadata": {
        "id": "ohK0QyZjtqW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda # install cuda\n"
      ],
      "metadata": {
        "id": "350tqdkrteeV",
        "outputId": "56eb1fd0-9315-49f8-8740-194a6685ac53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.9/dist-packages (2022.2.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.9/dist-packages (from pycuda) (2022.1.14)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile a.py\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "import numpy as np\n",
        "import pycuda.driver as drv\n",
        "\n",
        "mod_ker = SourceModule(\"\"\"\n",
        "  #include <stdint.h>\n",
        "  __global__ void group_data(uint32_t *a)\n",
        "  {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    printf(\"loca is %zu:%zu \\\\n\", idx,idy);\n",
        "    // out[idx][idy]=2;\n",
        "  }\n",
        "  \"\"\")\n",
        "group_data_gpu=mod_ker.get_function('group_data')\n",
        "\n",
        "numdata=np.array(numdata,dtype=np.uint32)\n",
        "numdata_gpu=gpuarray.to_gpu(numdata)\n",
        "\n",
        "#loop in CPU\n",
        "\n",
        "print('size',numdata_gpu.shape)\n",
        "# out_gpu=gpuarray.empty_like(numdata_gpu)\n",
        "group_data_gpu(numdata_gpu,block=(1024,1,1), grid=(1,1,1))\n",
        "# drv.Context.synchronize()\n",
        "# print(out_gpu)\n"
      ],
      "metadata": {
        "id": "iIn8V5HOvG-O",
        "outputId": "10c41a3a-b147-4967-abd0-aa1e162c2941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-69c3d8b4ebf6>:9: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "kernel.cu(8): warning #181-D: argument is incompatible with corresponding format string conversion\n",
            "\n",
            "kernel.cu(8): warning #181-D: argument is incompatible with corresponding format string conversion\n",
            "\n",
            "\n",
            "  mod_ker = SourceModule(\"\"\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LogicError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-69c3d8b4ebf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m mod_ker = SourceModule(\"\"\"\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m#include <stdint.h>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0m__global__\u001b[0m \u001b[0mvoid\u001b[0m \u001b[0mgroup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muint32_t\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLogicError\u001b[0m: cuModuleLoadDataEx failed: an illegal memory access was encountered - "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python a.py\n",
        "# build and debug the cuda c code\n",
        "#!nvcc --cubin -arch sm_75 -I/usr/local/lib/python3.9/dist-packages/pycuda/cuda /tmp/tmp3vuxop3u/kernel.cu\n"
      ],
      "metadata": {
        "id": "fn-16aRBuYEm",
        "outputId": "2a7bcedd-d5c7-4d66-f69b-49ee6e500dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/a.py\", line 19, in <module>\n",
            "    numdata=np.array(numdata,dtype=np.uint32)\n",
            "NameError: name 'numdata' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "bSAkS6e2Jk38",
        "outputId": "0d965e81-81f4-49aa-b4ea-4ba767c74470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(355, 662)\n",
            "uint8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LogicError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-fb3b4959ba54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#nbtes determines the number of bytes for the numpy array a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mimg_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#Copies the memory from CPU to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLogicError\u001b[0m: cuMemAlloc failed: an illegal memory access was encountered"
          ]
        }
      ],
      "source": [
        "#Example: loop 2 dimensional array\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import cv2 \n",
        "\n",
        "import pycuda.autoinit\n",
        "\n",
        "img = cv2.imread('drive/MyDrive/test.jpg',0)\n",
        "img_size=img.shape\n",
        "print(img_size)\n",
        "print(img.dtype)\n",
        "\n",
        "#nbtes determines the number of bytes for the numpy array a\n",
        "img_gpu = cuda.mem_alloc(img.nbytes)\n",
        "#Copies the memory from CPU to GPU\n",
        "cuda.memcpy_htod(img_gpu, img)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "#include <stdio.h>\n",
        "__global__ void AHE(unsigned char *a, int row, int col)\n",
        "{\n",
        "int i = threadIdx.x+ blockIdx.x* blockDim.x;\n",
        "int j = threadIdx.y+ blockIdx.y* blockDim.y;\n",
        "\n",
        "if(i==0 && j ==0)\n",
        "printf(\"Output array \\n\");\n",
        "\n",
        "if(i <row && j < col)\n",
        "{\n",
        "    int val = int(a[j + i*col]);\n",
        "    printf(\" %d\", val);\n",
        "}\n",
        "}\n",
        "\"\"\")\n",
        "#Gives you the number of columns\n",
        "col = np.int32(img.shape[-1])\n",
        "row = np.int32(img.shape[0])\n",
        "func = mod.get_function(\"AHE\")\n",
        "func(img_gpu, row, col, block=(32,32,1))\n",
        "img_ahe = np.empty_like(img)\n",
        "cuda.memcpy_dtoh(img_ahe, img_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBQ0blkNJnIg"
      },
      "outputs": [],
      "source": [
        "func = mod.get_function(\"doublify\")\n",
        "func(a_gpu, block=(4,4,1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdGxS_NpS1Fo",
        "outputId": "42d863c2-2a4e-4425-dd82-05f2b6ee5741"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ef82NDPJqWV"
      },
      "outputs": [],
      "source": [
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(a_doubled)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXx_p97mJs4Z"
      },
      "outputs": [],
      "source": [
        "b = numpy.random.randn(4,4)\n",
        "b = b.astype(numpy.float32)\n",
        "c = numpy.random.randn(4,4)\n",
        "c = c.astype(numpy.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQYD348qKgva"
      },
      "outputs": [],
      "source": [
        "mod2 = SourceModule(\"\"\"\n",
        "  __global__ void add2(float *a, float *b)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] += b[idx];\n",
        "  }\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs_5Hb-6Kr-C"
      },
      "outputs": [],
      "source": [
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "cuda.memcpy_htod(c_gpu, c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwA4tpOtLE5_"
      },
      "outputs": [],
      "source": [
        "func = mod2.get_function(\"add2\")\n",
        "func(b_gpu,c_gpu, block=(4,4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zN8iBYDM_00"
      },
      "outputs": [],
      "source": [
        "added = numpy.empty_like(b)\n",
        "cuda.memcpy_dtoh(added, b_gpu)\n",
        "print(added)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBVoR8ANgx5"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1. Write a cuda kernel to find the elementwise square of a matrix\n",
        "2. Write a cuda kernel to find a matrix, which when added to the given matrix results in every element being equal to zero\n",
        "3. Write a cuda kernel to multiply two matrices:\n",
        "    1. Assume square matrices, with dimensions < 1024\n",
        "    2. Assume square matrices, with dimensions > 1024\n",
        "    3. Assume non-square matrices, with dimensions > 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBYr6BUWNuLe"
      },
      "outputs": [],
      "source": [
        "1. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pycuda workshop",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}