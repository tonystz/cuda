{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonystz/gitpod/blob/main/strings_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda # install cuda\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "6QAStcPlRxWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ttt = np.asarray([ \"stuff\" + str(i)  for i in range(0,2) ])\n",
        "\n",
        "print( ttt.dtype, type(ttt[0]) ) \n",
        "print(ttt)\n",
        "\n",
        "s= np.array(['abcdf'], dtype=np.str_)\n",
        "print( s.dtype, type(s[0]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIfpULJwlMWY",
        "outputId": "ba6099cf-a029-49e5-f2fa-def36e7fe318"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<U6 <class 'numpy.str_'>\n",
            "['stuff0' 'stuff1']\n",
            "<U5 <class 'numpy.str_'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile s.py\n",
        "#!python \n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "import numpy as np\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    #include <stdio.h>\n",
        "\n",
        "    __global__ void say_hi( char *out_gpu)\n",
        "    { \n",
        "      int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "      printf(\"thread id: [%d]  %s\\\\n\",idx,out_gpu[idx]);\n",
        "      //print c-str\n",
        "      for (int i=0;i<4;i++){\n",
        "        printf(\"%c\",out_gpu[i]);\n",
        "      }\n",
        "\n",
        "      printf(\" >end\\\\n\");\n",
        "      printf(\"test:%s\\\\n\",out_gpu);\n",
        "\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "func = mod.get_function(\"say_hi\")\n",
        "\n",
        "\n",
        "s= np.array(['s12345'], dtype=np.str_)\n",
        "print('shape:',s.shape)\n",
        "print(s,s.data)\n",
        "\n",
        "s_gpu = gpuarray.to_gpu(s)\n",
        "func(s_gpu,block=(s.size,1,1),grid=(1,1,1))\n",
        "print('modify:',s_gpu.get())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3vCpSIuULQt",
        "outputId": "15bfc350-4e43-449d-8eb1-b1890235a582"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting s.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNIVqz_mUS2u",
        "outputId": "837abd48-09ca-4120-bc33-267ed8fe86b2"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (1,)\n",
            "['s12345'] <memory at 0x7f800023c580>\n",
            "thread id: [0]  (null)\n",
            "s\u0000\u0000\u0000 >end\n",
            "test:s\n",
            "modify: ['s12345']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile t389.cu\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "\n",
        "#define nTPB 256\n",
        "\n",
        "__global__ void kern_1D(char *data, unsigned *indices, unsigned num_strings){\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "  if (idx < num_strings)\n",
        "    printf(\"Hello from thread %d, my string is %s\\n\", idx, data+indices[idx]);\n",
        "}\n",
        "\n",
        "__global__ void kern_2D(char **data, unsigned num_strings){\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "  if (idx < num_strings)\n",
        "    printf(\"Hello from thread %d, my string is %s\\n\", idx, data[idx]);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  const int num_strings = 3;\n",
        "  const char s0[] = \"s1\\0\";\n",
        "  const char s1[] = \"s2\\0\";\n",
        "  const char s2[] = \"sstz3\\0\";\n",
        "  int ds[num_strings];\n",
        "  ds[0] = sizeof(s0)/sizeof(char);\n",
        "  ds[1] = sizeof(s1)/sizeof(char);\n",
        "  ds[2] = sizeof(s2)/sizeof(char);\n",
        "  // pretend we have a dynamically allocated char** array\n",
        "  char **data;\n",
        "  data = (char **)malloc(num_strings*sizeof(char *));\n",
        "  data[0] = (char *)malloc(ds[0]*sizeof(char));\n",
        "  data[1] = (char *)malloc(ds[1]*sizeof(char));\n",
        "  data[2] = (char *)malloc(ds[2]*sizeof(char));\n",
        "  // initialize said array\n",
        "  strcpy(data[0], s0);\n",
        "  strcpy(data[1], s1);\n",
        "  strcpy(data[2], s2);\n",
        "  // method 1: \"flattening\"\n",
        "  char *fdata = (char *)malloc((ds[0]+ds[1]+ds[2])*sizeof(char));\n",
        "  unsigned *ind   = (unsigned *)malloc(num_strings*sizeof(unsigned));\n",
        "  unsigned next = 0;\n",
        "  for (int i = 0; i < num_strings; i++){\n",
        "    strcpy(fdata+next, data[i]);\n",
        "    ind[i] = next;\n",
        "    next += ds[i];}\n",
        "  //copy to device\n",
        "  char *d_fdata;\n",
        "  unsigned *d_ind;\n",
        "  cudaMalloc(&d_fdata, next*sizeof(char));\n",
        "  cudaMalloc(&d_ind, num_strings*sizeof(unsigned));\n",
        "  cudaMemcpy(d_fdata, fdata, next*sizeof(char), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_ind, ind, num_strings*sizeof(unsigned), cudaMemcpyHostToDevice);\n",
        "  printf(\"method 1:\\n\");\n",
        "  kern_1D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(d_fdata, d_ind, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "  //method 2: \"2D\" (pointer-to-pointer) array\n",
        "  char **d_data;\n",
        "  cudaMalloc(&d_data, num_strings*sizeof(char *));\n",
        "  char **d_temp_data;\n",
        "  d_temp_data = (char **)malloc(num_strings*sizeof(char *));\n",
        "  for (int i = 0; i < num_strings; i++){\n",
        "    cudaMalloc(&(d_temp_data[i]), ds[i]*sizeof(char));\n",
        "    cudaMemcpy(d_temp_data[i], data[i], ds[i]*sizeof(char), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_data+i, &(d_temp_data[i]), sizeof(char *), cudaMemcpyHostToDevice);}\n",
        "  printf(\"method 2:\\n\");\n",
        "  kern_2D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(d_data, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "  // method 3: managed allocations\n",
        "  // start over with a managed char** array\n",
        "  char **m_data;\n",
        "  cudaMallocManaged(&m_data, num_strings*sizeof(char *));\n",
        "  cudaMallocManaged(&(m_data[0]), ds[0]*sizeof(char));\n",
        "  cudaMallocManaged(&(m_data[1]), ds[1]*sizeof(char));\n",
        "  cudaMallocManaged(&(m_data[2]), ds[2]*sizeof(char));\n",
        "  // initialize said array\n",
        "  strcpy(m_data[0], s0);\n",
        "  strcpy(m_data[1], s1);\n",
        "  strcpy(m_data[2], s2);\n",
        "  // call kernel directly on managed data\n",
        "  printf(\"method 3:\\n\");\n",
        "  kern_2D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(m_data, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LixIpFBrd7x",
        "outputId": "416af874-847f-4451-93ab-16da37b3bc1c"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting t389.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o t389 t389.cu\n",
        "!compute-sanitizer ./t389"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sSHVTI7rrBI",
        "outputId": "91e25e6f-d4b9-4a25-e255-18c9056d21f3"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "method 1:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "method 2:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "method 3:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile s2.py\n",
        "import time\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import math\n",
        "from sys import getsizeof\n",
        "\n",
        "import pycuda.autoinit\n",
        "\n",
        "kernel_code1 = \"\"\"\n",
        "__global__ void test1(char** d_wordList) {\n",
        "    (d_wordList[blockIdx.x][threadIdx.x])++;      \n",
        "}\n",
        "    \"\"\"\n",
        "\n",
        "kernel_code2 = \"\"\"\n",
        "__global__ void test2(char* d_wordList, size_t *offsets) {\n",
        "\n",
        "    int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "    printf(\"Hello from thread %d, my string is %s\\\\n\", idx, d_wordList+offsets[idx]);\n",
        "    (d_wordList[offsets[blockIdx.x] + threadIdx.x])++;\n",
        "}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code1)\n",
        "ker_test1 = mod.get_function(\"test1\")\n",
        "\n",
        "\n",
        "\n",
        "wordList = ['asd','bsd','csd']\n",
        "\n",
        "d_words = []\n",
        "\n",
        "for word in wordList:\n",
        "    d_words.append(gpuarray.to_gpu(np.array(word, dtype=str)))\n",
        "\n",
        "d_wordList = gpuarray.to_gpu(np.array([word.ptr for word in d_words], dtype=np.uintp))\n",
        "\n",
        "ker_test1(d_wordList, block=(3,1,1), grid=(3,1,1))\n",
        "\n",
        "for word in d_words:\n",
        "  result = word.get()\n",
        "  print(result)\n",
        "\n",
        "mod2 = compiler.SourceModule(kernel_code2)\n",
        "ker_test2 = mod2.get_function(\"test2\")\n",
        "wordlist2 = np.array(['asdbsdcsd'], dtype=np.str_)\n",
        "d_words2 = gpuarray.to_gpu(np.array(['asd','bsd','csd'], dtype=np.str_))\n",
        "offsets = gpuarray.to_gpu(np.array([0,3,6,9], dtype=np.uint64))\n",
        "ker_test2(d_words2, offsets, block=(3,1,1), grid=(1,1,1))\n",
        "h_words2 = d_words2.get()\n",
        "print(h_words2)\n"
      ],
      "metadata": {
        "id": "vo6DMw4Ozkaz",
        "outputId": "92a9d928-7a7e-46ed-dbaa-5eeb07db8b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting s2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s2.py"
      ],
      "metadata": {
        "id": "rZSN14p-z1rR",
        "outputId": "4144aeec-c395-410f-8798-46bd46a340d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "êÖ¢sd\n",
            "êÖ£sd\n",
            "êÖ§sd\n",
            "Hello from thread 0, my string is a\n",
            "Hello from thread 1, my string is \n",
            "Hello from thread 2, my string is \n",
            "['êÖ¢sd' 'bsd' 'csd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7A24j3mRsTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oM8mVJsjRvSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YLboziJbB1ds"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tamlFvddB1KN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}