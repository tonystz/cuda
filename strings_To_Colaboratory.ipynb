{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonystz/gitpod/blob/main/strings_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda # install cuda\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "6QAStcPlRxWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ttt = np.asarray([ \"stuff\" + str(i)  for i in range(0,2) ])\n",
        "\n",
        "print( ttt.dtype, type(ttt[0]) ) \n",
        "print(ttt)\n",
        "\n",
        "s= np.array(['abcdf'], dtype=object)\n",
        "print( s.dtype, type(s[0]) )\n",
        "\n",
        "#print(\"ctype:\",np.ctypeslib.as_ctypes_type(s.dtype))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIfpULJwlMWY",
        "outputId": "b5f001a6-78bc-4406-f493-b7650a4b6f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<U6 <class 'numpy.str_'>\n",
            "['stuff0' 'stuff1']\n",
            "object <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## string test"
      ],
      "metadata": {
        "id": "MkqQD552fAXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile s2.py\n",
        "import time\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import math\n",
        "from sys import getsizeof\n",
        "\n",
        "import pycuda.autoinit\n",
        "\n",
        "kernel_code1 = \"\"\"\n",
        "__global__ void test1(char** d_wordList) {\n",
        "    (d_wordList[blockIdx.x][threadIdx.x])++;      \n",
        "}\n",
        "    \"\"\"\n",
        "\n",
        "kernel_code2 = \"\"\"\n",
        "__global__ void test2(char* d_wordList, size_t *offsets) {\n",
        "\n",
        "    int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "    printf(\"index: threadIdx.x=%d blockIdx.x=%d  blockDim.x=%d \\\\n\",threadIdx.x,blockIdx.x,blockDim.x);\n",
        "    printf(\"Hello from thread %d, my string is %s ,offsets:%u \\\\n\", idx, d_wordList+offsets[idx],offsets[blockIdx.x]);\n",
        "    (d_wordList[offsets[blockIdx.x] + threadIdx.x])++;\n",
        "}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code1)\n",
        "ker_test1 = mod.get_function(\"test1\")\n",
        "\n",
        "\n",
        "\n",
        "wordList = ['asd','bsd','csd']\n",
        "\n",
        "d_words = []\n",
        "\n",
        "for word in wordList:\n",
        "    d_words.append(gpuarray.to_gpu(np.array(word, dtype=str)))\n",
        "\n",
        "d_wordList = gpuarray.to_gpu(np.array([word.ptr for word in d_words], dtype=np.uintp))\n",
        "\n",
        "ker_test1(d_wordList, block=(3,1,1), grid=(3,1,1))\n",
        "\n",
        "for word in d_words:\n",
        "  result = word.get()\n",
        "  print(result)\n",
        "\n",
        "mod2 = compiler.SourceModule(kernel_code2)\n",
        "ker_test2 = mod2.get_function(\"test2\")\n",
        "\n",
        "d_words2 = gpuarray.to_gpu(np.array(['asd','bsd','csd'], dtype=np.string_))\n",
        "offsets = gpuarray.to_gpu(np.array([0,3,6,9], dtype=np.uint64))\n",
        "ker_test2(d_words2, offsets, block=(3,1,1), grid=(1,1,1))\n",
        "h_words2 = d_words2.get()\n",
        "print(h_words2)"
      ],
      "metadata": {
        "id": "jMJcWbEffD9I",
        "outputId": "12cf279b-319d-40f4-d492-32770bc72455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting s2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s2.py"
      ],
      "metadata": {
        "id": "tZPgiuMAfGdZ",
        "outputId": "bd6dfc70-fd5c-4c53-c223-ddd92a47679e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "êÖ¢sd\n",
            "êÖ£sd\n",
            "êÖ§sd\n",
            "index: threadIdx.x=0 blockIdx.x=0  blockDim.x=3 \n",
            "index: threadIdx.x=1 blockIdx.x=0  blockDim.x=3 \n",
            "index: threadIdx.x=2 blockIdx.x=0  blockDim.x=3 \n",
            "Hello from thread 0, my string is asdbsdcsd ,offsets:0 \n",
            "Hello from thread 1, my string is bsdcsd ,offsets:0 \n",
            "Hello from thread 2, my string is csd ,offsets:0 \n",
            "[b'bte' b'bsd' b'csd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## all string size must equal?"
      ],
      "metadata": {
        "id": "cWZj7ByhRDsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile s.py\n",
        "#!python \n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "import numpy as np\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    #include <stdio.h>\n",
        "    const int strLen=6;\n",
        "    __global__ void say_hi(char*out_gpu, unsigned int *s_offset_gpu)\n",
        "    { \n",
        "      int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "      //printf(\"index: threadIdx.x=%d blockIdx.x=%d  blockDim.x=%d \\\\n\",threadIdx.x,blockIdx.x,blockDim.x);\n",
        "      //printf(\"thread id: [%d]  offset:%d \\\\n\",idx,s_offset_gpu[idx]);\n",
        "      printf(\"thread id: [%d]  offset:%d  get str:%s  strlen=%d \\\\n\",idx,s_offset_gpu[idx],out_gpu+s_offset_gpu[idx]+1, strLen);\n",
        "\n",
        "      // string len is 6\n",
        "      char sub[strLen+1];\n",
        "      for(int i = 0; i<strLen; i++)\n",
        "      {\n",
        "        sub[i]=out_gpu[idx*strLen+i];\n",
        "      }\n",
        "      printf(\"substring:%s\\\\n\",sub);\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "say_hi = mod.get_function(\"say_hi\")\n",
        "\n",
        "#padding string with \\0 char\n",
        "s= np.array(['abcmh\\0','edfg\\0\\0','s12wc\\0','h45q\\0\\0'], dtype=np.string_)\n",
        "\n",
        "offset=[0]\n",
        "for i in s:\n",
        "  offset.append(offset[-1]+len(i))\n",
        "s_offset=np.array(offset,dtype=np.uint32)\n",
        "print('shape:',s.shape)\n",
        "print(s,s.data)\n",
        "print('offset:',s_offset,s_offset.shape)\n",
        "\n",
        "s_gpu = gpuarray.to_gpu(s)\n",
        "s_offset_gpu = gpuarray.to_gpu(s_offset)\n",
        "\n",
        "say_hi(s_gpu,s_offset_gpu,block=(s.size,1,1),grid=(1,1,1))\n",
        "print('modify:',s_gpu.get(),s_offset_gpu.get())\n",
        "\n",
        "print(\"s_offset ctype:\",np.ctypeslib.as_ctypes_type(s_offset.dtype))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3vCpSIuULQt",
        "outputId": "ff07d2ae-b9d8-404b-c304-a0740d15ad8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing s.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNIVqz_mUS2u",
        "outputId": "b4151573-33b4-42ff-fee1-fef0acfe1054"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (4,)\n",
            "[b'abcmh' b'edfg' b's12wc' b'h45q'] <memory at 0x7f4a8493d580>\n",
            "offset: [ 0  5  9 14 18] (5,)\n",
            "thread id: [0]  offset:0  get str:bcmh  strlen=6 \n",
            "thread id: [1]  offset:5  get str:edfg  strlen=6 \n",
            "thread id: [2]  offset:9  get str:  strlen=6 \n",
            "thread id: [3]  offset:14  get str:wc  strlen=6 \n",
            "substring:abcmh\n",
            "substring:edfg\n",
            "substring:s12wc\n",
            "substring:h45q\n",
            "modify: [b'abcmh' b'edfg' b's12wc' b'h45q'] [ 0  5  9 14 18]\n",
            "s_offset ctype: <class 'ctypes.c_uint'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test un-equal string process?"
      ],
      "metadata": {
        "id": "q0aII8SvieuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile su.py\n",
        "#!python \n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "import numpy as np\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    #include <stdio.h>\n",
        "\n",
        "    __global__ void say_hi(char*out_gpu, unsigned int *s_offset_gpu)\n",
        "    {  //max string len is 13\n",
        "      const int strLen=13;\n",
        "      int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "      //printf(\"index: threadIdx.x=%d blockIdx.x=%d  blockDim.x=%d \\\\n\",threadIdx.x,blockIdx.x,blockDim.x);\n",
        "      //printf(\"thread id: [%d]  offset:%d \\\\n\",idx,s_offset_gpu[idx]);\n",
        "      printf(\"thread id: [%d]  offset:%d  get str:%s\\\\n\",idx,s_offset_gpu[idx],out_gpu+s_offset_gpu[idx]);\n",
        "  \n",
        "      char sub[strLen+1];\n",
        "      for(int i = 0; i<strLen; i++)\n",
        "      {\n",
        "        sub[i]=out_gpu[idx*strLen+i];\n",
        "      }\n",
        "      printf(\"thread[%d]:substring:%s\\\\n\",idx,sub);\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "say_hi = mod.get_function(\"say_hi\")\n",
        "\n",
        "\n",
        "s= np.array(['abc\\0','edfg\\0','stz12345678b\\0'], dtype=np.string_)\n",
        "\n",
        "offset=[0]\n",
        "for i in s:\n",
        "  offset.append(offset[-1]+len(i))\n",
        "s_offset=np.array(offset,dtype=np.uint32)\n",
        "print('shape:',s.shape)\n",
        "print(s,s.data)\n",
        "print('offset:',s_offset,s_offset.shape)\n",
        "\n",
        "s_gpu = gpuarray.to_gpu(s)\n",
        "s_offset_gpu = gpuarray.to_gpu(s_offset)\n",
        "\n",
        "say_hi(s_gpu,s_offset_gpu,block=(s.size,1,1),grid=(1,1,1))\n",
        "print('modify:',s_gpu.get(),s_offset_gpu.get())\n",
        "\n",
        "print(\"s_offset ctype:\",np.ctypeslib.as_ctypes_type(s_offset.dtype))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaQ8-EtoieRb",
        "outputId": "e852d9eb-b897-4d0a-80dc-e36a0a6a92f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting su.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python su.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJFwn3gkiy7D",
        "outputId": "13c03ef6-5a28-4635-e5b9-d37e8e2ba939"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (3,)\n",
            "[b'abc' b'edfg' b'stz12345678b'] <memory at 0x7f01c3dbb580>\n",
            "offset: [ 0  3  7 19] (4,)\n",
            "thread id: [0]  offset:0  get str:abc\n",
            "thread id: [1]  offset:3  get str:\n",
            "thread id: [2]  offset:7  get str:\n",
            "thread[0]:substring:abc\n",
            "thread[1]:substring:edfg\n",
            "thread[2]:substring:stz12345678b\n",
            "modify: [b'abc' b'edfg' b'stz12345678b'] [ 0  3  7 19]\n",
            "s_offset ctype: <class 'ctypes.c_uint'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile t389.cu\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "\n",
        "#define nTPB 256\n",
        "\n",
        "__global__ void kern_1D(char *data, unsigned *indices, unsigned num_strings){\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "  if (idx < num_strings)\n",
        "    printf(\"Hello from thread %d, offset=%d, my string is %s\\n\", idx, indices[idx],data+indices[idx]);\n",
        "}\n",
        "\n",
        "__global__ void kern_2D(char **data, unsigned num_strings){\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x;\n",
        "  if (idx < num_strings)\n",
        "    printf(\"Hello from thread %d, my string is %s\\n\", idx, data[idx]);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  const int num_strings = 3;\n",
        "  const char s0[] = \"s1\\0\";\n",
        "  const char s1[] = \"s2\\0\";\n",
        "  const char s2[] = \"sstz3\";\n",
        "  int ds[num_strings];\n",
        "  ds[0] = sizeof(s0)/sizeof(char);\n",
        "  ds[1] = sizeof(s1)/sizeof(char);\n",
        "  ds[2] = sizeof(s2)/sizeof(char);\n",
        "  // pretend we have a dynamically allocated char** array\n",
        "  char **data;\n",
        "  data = (char **)malloc(num_strings*sizeof(char *));\n",
        "  data[0] = (char *)malloc(ds[0]*sizeof(char));\n",
        "  data[1] = (char *)malloc(ds[1]*sizeof(char));\n",
        "  data[2] = (char *)malloc(ds[2]*sizeof(char));\n",
        "  // initialize said array\n",
        "  strcpy(data[0], s0);\n",
        "  strcpy(data[1], s1);\n",
        "  strcpy(data[2], s2);\n",
        "  // method 1: \"flattening\"\n",
        "  char *fdata = (char *)malloc((ds[0]+ds[1]+ds[2])*sizeof(char));\n",
        "  unsigned *ind   = (unsigned *)malloc(num_strings*sizeof(unsigned));\n",
        "  unsigned next = 0;\n",
        "  for (int i = 0; i < num_strings; i++){\n",
        "    strcpy(fdata+next, data[i]);\n",
        "    ind[i] = next;\n",
        "    next += ds[i];}\n",
        "  //copy to device\n",
        "  char *d_fdata;\n",
        "  unsigned *d_ind;\n",
        "  cudaMalloc(&d_fdata, next*sizeof(char));\n",
        "  cudaMalloc(&d_ind, num_strings*sizeof(unsigned));\n",
        "  cudaMemcpy(d_fdata, fdata, next*sizeof(char), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_ind, ind, num_strings*sizeof(unsigned), cudaMemcpyHostToDevice);\n",
        "  printf(\"method 1: %d  --> %d\\n\",(num_strings+nTPB-1)/nTPB,nTPB);\n",
        "  kern_1D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(d_fdata, d_ind, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "  //method 2: \"2D\" (pointer-to-pointer) array\n",
        "  char **d_data;\n",
        "  cudaMalloc(&d_data, num_strings*sizeof(char *));\n",
        "  char **d_temp_data;\n",
        "  d_temp_data = (char **)malloc(num_strings*sizeof(char *));\n",
        "  for (int i = 0; i < num_strings; i++){\n",
        "    cudaMalloc(&(d_temp_data[i]), ds[i]*sizeof(char));\n",
        "    cudaMemcpy(d_temp_data[i], data[i], ds[i]*sizeof(char), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_data+i, &(d_temp_data[i]), sizeof(char *), cudaMemcpyHostToDevice);}\n",
        "  printf(\"method 2:\\n\");\n",
        "  kern_2D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(d_data, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "  // method 3: managed allocations\n",
        "  // start over with a managed char** array\n",
        "  char **m_data;\n",
        "  cudaMallocManaged(&m_data, num_strings*sizeof(char *));\n",
        "  cudaMallocManaged(&(m_data[0]), ds[0]*sizeof(char));\n",
        "  cudaMallocManaged(&(m_data[1]), ds[1]*sizeof(char));\n",
        "  cudaMallocManaged(&(m_data[2]), ds[2]*sizeof(char));\n",
        "  // initialize said array\n",
        "  strcpy(m_data[0], s0);\n",
        "  strcpy(m_data[1], s1);\n",
        "  strcpy(m_data[2], s2);\n",
        "  // call kernel directly on managed data\n",
        "  printf(\"method 3:\\n\");\n",
        "  kern_2D<<<(num_strings+nTPB-1)/nTPB, nTPB>>>(m_data, num_strings);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LixIpFBrd7x",
        "outputId": "f48e4d5c-99a7-452a-9cc2-51693cd31c37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting t389.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc t389.cu -o t389\n",
        "!nvprof ./t389"
      ],
      "metadata": {
        "id": "ffznc4yfbUXI",
        "outputId": "153e0e69-3813-4e12-e812-4d66e4f828d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4961== NVPROF is profiling process 4961, command: ./t389\n",
            "method 1: 1  --> 256\n",
            "Hello from thread 0, offset=0, my string is s1\n",
            "Hello from thread 1, offset=4, my string is s2\n",
            "Hello from thread 2, offset=8, my string is sstz3\n",
            "method 2:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "method 3:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "==4961== Profiling application: ./t389\n",
            "==4961== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   82.09%  591.70us         2  295.85us  98.494us  493.20us  kern_2D(char**, unsigned int)\n",
            "                   16.23%  116.99us         1  116.99us  116.99us  116.99us  kern_1D(char*, unsigned int*, unsigned int)\n",
            "                    1.67%  12.062us         8  1.5070us  1.4080us  2.0160us  [CUDA memcpy HtoD]\n",
            "      API calls:   93.68%  338.21ms         6  56.368ms  3.1700us  338.19ms  cudaMalloc\n",
            "                    5.70%  20.578ms         4  5.1446ms  6.1590us  20.460ms  cudaMallocManaged\n",
            "                    0.30%  1.0906ms         1  1.0906ms  1.0906ms  1.0906ms  cuDeviceGetPCIBusId\n",
            "                    0.21%  774.33us         3  258.11us  111.84us  526.92us  cudaDeviceSynchronize\n",
            "                    0.04%  155.24us       101  1.5370us     130ns  67.258us  cuDeviceGetAttribute\n",
            "                    0.03%  114.05us         3  38.017us  12.667us  66.446us  cudaLaunchKernel\n",
            "                    0.02%  84.926us         8  10.615us  5.5430us  28.243us  cudaMemcpy\n",
            "                    0.01%  27.595us         1  27.595us  27.595us  27.595us  cuDeviceGetName\n",
            "                    0.00%  1.8000us         3     600ns     235ns  1.2940us  cuDeviceGetCount\n",
            "                    0.00%  1.0710us         2     535ns     275ns     796ns  cuDeviceGet\n",
            "                    0.00%     525ns         1     525ns     525ns     525ns  cuModuleGetLoadingMode\n",
            "                    0.00%     496ns         1     496ns     496ns     496ns  cuDeviceTotalMem\n",
            "                    0.00%     244ns         1     244ns     244ns     244ns  cuDeviceGetUuid\n",
            "\n",
            "==4961== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       2  32.000KB  4.0000KB  60.000KB  64.00000KB  10.91100us  Host To Device\n",
            "       1         -         -         -           -  392.5030us  Gpu page fault groups\n",
            "Total CPU Page faults: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o t389 t389.cu\n",
        "!compute-sanitizer ./t389"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sSHVTI7rrBI",
        "outputId": "f77c3cd3-4888-46be-d838-09223cb20593"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "method 1: 1  --> 256\n",
            "Hello from thread 0, offset=0, my string is s1\n",
            "Hello from thread 1, offset=4, my string is s2\n",
            "Hello from thread 2, offset=8, my string is sstz3\n",
            "method 2:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "method 3:\n",
            "Hello from thread 0, my string is s1\n",
            "Hello from thread 1, my string is s2\n",
            "Hello from thread 2, my string is sstz3\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test struct with number\n",
        "https://github.com/inducer/pycuda/blob/main/examples/demo_struct.py"
      ],
      "metadata": {
        "id": "UIXOg0vKeURO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo_struct.py\n",
        "# prepared invocations and structures -----------------------------------------\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "import struct\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "class DoubleOpStruct:\n",
        "    mem_size = 8 + numpy.uintp(0).nbytes\n",
        "    def __init__(self, array, struct_arr_ptr):\n",
        "        self.data = cuda.to_device(array)\n",
        "        self.shape, self.dtype = array.shape, array.dtype\n",
        "\n",
        "        packed_args = struct.pack(\"ixP\", array.size, numpy.uintp(self.data))\n",
        "        cuda.memcpy_htod(struct_arr_ptr, packed_args)\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(cuda.from_device(self.data, self.shape, self.dtype))\n",
        "\n",
        "struct_arr = cuda.mem_alloc(2 * DoubleOpStruct.mem_size)\n",
        "do2_ptr = int(struct_arr) + DoubleOpStruct.mem_size\n",
        "\n",
        "array1 = DoubleOpStruct(numpy.array([1, 2, 3], dtype=numpy.float32), struct_arr)\n",
        "array2 = DoubleOpStruct(numpy.array([0, 4], dtype=numpy.float32), do2_ptr)\n",
        "\n",
        "print(\"original arrays\")\n",
        "print(array1)\n",
        "print(array2)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    struct DoubleOperation {\n",
        "        int datalen, __padding; // so 64-bit ptrs can be aligned\n",
        "        float *ptr;\n",
        "    };\n",
        "\n",
        "\n",
        "    __global__ void double_array(DoubleOperation *a)\n",
        "    {\n",
        "        a = a + blockIdx.x;\n",
        "        for (int idx = threadIdx.x; idx < a->datalen; idx += blockDim.x)\n",
        "        {\n",
        "            float *a_ptr = a->ptr;\n",
        "            a_ptr[idx] *= 2;\n",
        "        }\n",
        "    }\n",
        "    \"\"\")\n",
        "func = mod.get_function(\"double_array\")\n",
        "func(struct_arr, block=(32, 1, 1), grid=(2, 1))\n",
        "\n",
        "print(\"doubled arrays\")\n",
        "print(array1)\n",
        "print(array2)\n",
        "\n",
        "func(numpy.uintp(do2_ptr), block=(32, 1, 1), grid=(1, 1))\n",
        "print(\"doubled second only\")\n",
        "print(array1)\n",
        "print(array2)\n",
        "\n",
        "if cuda.get_version() < (4, ):\n",
        "    func.prepare(\"P\", block=(32, 1, 1))\n",
        "    func.prepared_call((2, 1), struct_arr)\n",
        "else:\n",
        "    func.prepare(\"P\")\n",
        "    block = (32, 1, 1)\n",
        "    func.prepared_call((2, 1), block, struct_arr)\n",
        "\n",
        "\n",
        "print(\"doubled again\")\n",
        "print(array1)\n",
        "print(array2)\n",
        "\n",
        "if cuda.get_version() < (4, ):\n",
        "    func.prepared_call((1, 1), do2_ptr)\n",
        "else:\n",
        "    func.prepared_call((1, 1), block, do2_ptr)\n",
        "\n",
        "\n",
        "print(\"doubled second only again\")\n",
        "print(array1)\n",
        "print(array2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru4QqnvFwuka",
        "outputId": "fbea7d23-5018-4331-d3de-e9cf4d59c46e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demo_struct.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo_struct.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TifAInm2w9lS",
        "outputId": "e24729a4-f76f-4c70-e7c3-e0ef4250299c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original arrays\n",
            "[1. 2. 3.]\n",
            "[0. 4.]\n",
            "doubled arrays\n",
            "[2. 4. 6.]\n",
            "[0. 8.]\n",
            "doubled second only\n",
            "[2. 4. 6.]\n",
            "[ 0. 16.]\n",
            "doubled again\n",
            "[ 4.  8. 12.]\n",
            "[ 0. 32.]\n",
            "doubled second only again\n",
            "[ 4.  8. 12.]\n",
            "[ 0. 64.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test struct with string"
      ],
      "metadata": {
        "id": "o2nYLRLPxTwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python s2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZSN14p-z1rR",
        "outputId": "04928c59-f575-4c05-88a9-d0caa3d8b6b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "êÖ¢sd\n",
            "êÖ£sd\n",
            "êÖ§sd\n",
            "/content/s2.py:48: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "kernel.cu(7): warning #181-D: argument is incompatible with corresponding format string conversion\n",
            "\n",
            "\n",
            "  mod2 = compiler.SourceModule(kernel_code2)\n",
            "index: threadIdx.x=0 blockIdx.x=0  blockDim.x=3 \n",
            "index: threadIdx.x=1 blockIdx.x=0  blockDim.x=3 \n",
            "index: threadIdx.x=2 blockIdx.x=0  blockDim.x=3 \n",
            "Hello from thread 0, my string is asdbsdcsd ,offsets:0 \n",
            "Hello from thread 1, my string is bsdcsd ,offsets:0 \n",
            "Hello from thread 2, my string is csd ,offsets:0 \n",
            "[b'bte' b'bsd' b'csd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reference:\n",
        "https://stackoverflow.com/questions/34700999/cuda-passing-char-to-kernel/34712905\n",
        "https://documen.tician.de/pycuda/tutorial.html#structures\n",
        "https://stackoverflow.com/questions/48038577/pycuda-numpy-and-working-with-strings-in-general"
      ],
      "metadata": {
        "id": "x_WJoSceKlMM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}